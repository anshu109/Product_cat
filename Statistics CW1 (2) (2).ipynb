{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "string.punctuation;\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import ngrams\n",
    "from nltk.util import ngrams\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Level_1</th>\n",
       "      <th>Level_2</th>\n",
       "      <th>Level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerb cap help keep littl on head cov warm day ...</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tut ballet anym leap foxy fash ruffl tul toddl...</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>easy keep feel warm cozy inf toddl girl hoody ...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19    D06E\n",
       "1  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "2  tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19    D06E\n",
       "3  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "4  easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6    98CF"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"product-cat-dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Description', 'Level_1', 'Level_2', 'Level_3'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10649 entries, 0 to 10648\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Description  10637 non-null  object\n",
      " 1   Level_1      10649 non-null  object\n",
      " 2   Level_2      10649 non-null  object\n",
      " 3   Level_3      10649 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 332.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    12\n",
       "Level_1         0\n",
       "Level_2         0\n",
       "Level_3         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if data has missing values in the Description column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with missing values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Classes where the number of instances is < 10 (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D410C91A    504\n",
       "90A8B052    506\n",
       "014303D1    511\n",
       "4513C920    558\n",
       "4C3D8686    574\n",
       "3E1E0D78    579\n",
       "96F95EEC    587\n",
       "69286F45    797\n",
       "09BF5150    799\n",
       "EFEF723B    800\n",
       "2CEC27F1    859\n",
       "57164AC1    877\n",
       "AAC8EE56    890\n",
       "35E04739    896\n",
       "B092BA29    900\n",
       "Name: Level_1, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to Level_1 \n",
    "pd.value_counts(data['Level_1'],ascending=True)\n",
    "#data['Level_1'].value_counts().loc[lambda x : x<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A6301      1\n",
       "C66C5      1\n",
       "80D5B      6\n",
       "0864A     16\n",
       "08960     24\n",
       "AF6B9     36\n",
       "6C6B1     36\n",
       "915D4     47\n",
       "262E7     63\n",
       "F824F     72\n",
       "31FED     86\n",
       "D5531     88\n",
       "E69F5    109\n",
       "5E038    115\n",
       "E6162    117\n",
       "223B2    128\n",
       "36080    176\n",
       "77F62    229\n",
       "02FA0    264\n",
       "7AED7    282\n",
       "F4055    363\n",
       "ADAD6    410\n",
       "A04D3    411\n",
       "7B638    420\n",
       "C7E19    429\n",
       "94728    440\n",
       "390F1    441\n",
       "914A1    443\n",
       "74974    446\n",
       "9B69F    447\n",
       "CB803    448\n",
       "BAE8A    449\n",
       "B2DB4    449\n",
       "375FE    450\n",
       "5A8AB    450\n",
       "9D9EE    462\n",
       "C719A    482\n",
       "ACD06    504\n",
       "2D5A3    797\n",
       "Name: Level_2, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to Level_2\n",
    "pd.value_counts(data['Level_2'],ascending=True)\n",
    "#data['Level_2'].value_counts().loc[lambda x : x<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CF52      1\n",
       "E9F4      1\n",
       "DE3D      1\n",
       "DC8D      1\n",
       "B4A7      6\n",
       "96B8     16\n",
       "1000     24\n",
       "215F     33\n",
       "A104     36\n",
       "3AAD     36\n",
       "A2FA     47\n",
       "3DD3     53\n",
       "29B3     63\n",
       "7288     72\n",
       "6253     88\n",
       "DDD5    109\n",
       "6BE5    115\n",
       "2E14    117\n",
       "F213    128\n",
       "7C00    164\n",
       "C563    176\n",
       "1F75    199\n",
       "5AE1    229\n",
       "078B    264\n",
       "6539    282\n",
       "98CF    410\n",
       "C5B4    411\n",
       "0F8B    420\n",
       "D06E    429\n",
       "5912    439\n",
       "6856    441\n",
       "D97D    443\n",
       "62E8    446\n",
       "80C4    447\n",
       "2ABA    448\n",
       "627D    448\n",
       "21DA    449\n",
       "1F61    450\n",
       "AA6B    450\n",
       "05A0    462\n",
       "A0E2    482\n",
       "33D1    504\n",
       "28A7    797\n",
       "Name: Level_3, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to Level_3\n",
    "pd.value_counts(data['Level_3'],ascending=True)\n",
    "#data['Level_3'].value_counts().loc[lambda x : x<10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were no classes that had instances less than 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's write a Function to Prepare Text (4 marks)\n",
    "We will apply it to our DataFrame later on\n",
    "\n",
    "* This function receives a text string and performs the following:\n",
    "* Convert text to lower case\n",
    "* Remove punctuation marks\n",
    "* Apply stemming using the popular Snowball or Porter Stemmer (optional)\n",
    "* Apply NGram Tokenisation\n",
    "* Return the tokenised text as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "\n",
    "def process_text(text, n=2):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Convert text to lower case and remove all punctuation\n",
    "    2. Optionally apply stemming\n",
    "    3. Apply Ngram Tokenisation\n",
    "    4. Returns the tokenised text as a list\n",
    "    \"\"\"\n",
    "    # write steps here\n",
    "    text = text.lower() #description is already all lower case\n",
    "    text =\"\".join([i for i in text if i not in string.punctuation])\n",
    "    porter = PorterStemmer()\n",
    "    tokenised = ngrams(text.split(), n)\n",
    "    tokenised = [' '.join(tups) for tups in tokenised]\n",
    "    return tokenised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here were testing',\n",
       " 'were testing the',\n",
       " 'testing the processtext',\n",
       " 'the processtext function',\n",
       " 'processtext function results',\n",
       " 'function results are',\n",
       " 'results are as',\n",
       " 'are as follows']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example function call\n",
    "process_text(\"Here we're testing the process_text function, results are as follows:\", n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here were test',\n",
       " 'were test the',\n",
       " 'test the processtext',\n",
       " 'the processtext function',\n",
       " 'processtext function result',\n",
       " 'function result are',\n",
       " 'result are as',\n",
       " 'are as follow']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results should look like this:\n",
    "['here were test',\n",
    " 'were test the',\n",
    " 'test the processtext',\n",
    " 'the processtext function',\n",
    " 'processtext function result',\n",
    " 'function result are',\n",
    " 'result are as',\n",
    " 'are as follow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's apply TF-IDF to extract features from plain text (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [gerb cap, cap help, help keep, keep littl, li...\n",
       "1        [newborn inf, inf toddl, toddl boy, boy hoody,...\n",
       "2        [tut ballet, ballet anym, anym leap, leap foxy...\n",
       "3        [newborn inf, inf toddl, toddl boy, boy hoody,...\n",
       "4        [easy keep, keep feel, feel warm, warm cozy, c...\n",
       "                               ...                        \n",
       "10644    [term 10, 10 issu, issu on, on year, year subs...\n",
       "10645    [term 12, 12 issu, issu on, on year, year subs...\n",
       "10646    [term 9, 9 issu, issu on, on year, year subscr...\n",
       "10647    [term 26, 26 issu, issu on, on year, year subs...\n",
       "10648    [term 12, 12 issu, issu on, on year, year subs...\n",
       "Name: Description, Length: 10637, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Here you apply the process_text function to the Description column of the data\n",
    "data['Description'] = data.Description.apply(process_text)\n",
    "data['Description'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10637x16495 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 298233 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object\n",
    "# Then you pass the results to the bag of words tranformer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(data['Description'].str.join(' '))\n",
    "tfidf_matrix\n",
    "# See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10637, 16495)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the matrix shape\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use .transform on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of text file contents. Let's go ahead and check out how the bag-of-words counts for the entire corpus in a large, sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting matrix is in sparse format, we can transform it into dense\n",
    "# Code prepared for you so you can see what results look like\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16485</th>\n",
       "      <th>16486</th>\n",
       "      <th>16487</th>\n",
       "      <th>16488</th>\n",
       "      <th>16489</th>\n",
       "      <th>16490</th>\n",
       "      <th>16491</th>\n",
       "      <th>16492</th>\n",
       "      <th>16493</th>\n",
       "      <th>16494</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   16485  16486  16487  16488  16489  16490  16491  16492  16493  16494  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 16495 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an example result, the matrix will contain lots of zero values, that is expected\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the Data is Ready for Classifier Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test sets (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = tfidf_matrix\n",
    "y = data[[\"Level_1\", \"Level_2\", \"Level_3\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to reset index in each dataframe (depends on you how you do things)\n",
    "# done for you to make it clearer\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to take classes as separate columns (depends on you how you do things)\n",
    "class1 = y_train['Level_1'].astype(str)\n",
    "class2 = y_train['Level_2'].astype(str)\n",
    "class3 = y_train['Level_3'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for the three levels (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and save model for level 1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open(\"DecisionTreeClass1.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and save models for level 2\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "clf2.fit(X_train, class2)\n",
    "pickle.dump(clf2, open(\"DecisionTreeClass2.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and save models for level 3\n",
    "clf3 = DecisionTreeClassifier(random_state=0)\n",
    "clf3.fit(X_train, class3)\n",
    "pickle.dump(clf3, open(\"DecisionTreeClass3.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4C3D8686' '69286F45' 'EFEF723B' ... '35E04739' '014303D1' '4513C920']\n",
      "['74974' '2D5A3' 'CB803' ... 'B2DB4' '36080' '375FE']\n",
      "['62E8' '28A7' '627D' ... '21DA' 'C5B4' 'AA6B']\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty Dataframe with column names only (depends on you how you do things)\n",
    "results = pd.DataFrame(columns=['Level1_Pred', 'Level2_Pred', 'Level3_Pred'])\n",
    "\n",
    "## Here we reload the saved models and use them to predict the levels\n",
    "# load model for level 1 (done for you)\n",
    "with open('DecisionTreeClass1.sav', 'rb') as nb:\n",
    "    model = pickle.load(nb)\n",
    "\n",
    "## loop through the test data, predict level 1, then based on that predict level 2\n",
    "## and based on level 2 predict level 3 (you need to load saved models accordingly)\n",
    "print(model.predict(X_test))\n",
    "\n",
    "with open('DecisionTreeClass2.sav', 'rb') as nb:\n",
    "    model2 = pickle.load(nb)\n",
    "print(model2.predict(X_test))\n",
    "\n",
    "with open('DecisionTreeClass3.sav', 'rb') as nb:\n",
    "    model3 = pickle.load(nb)\n",
    "print(model3.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Level1_Pred\"] = model.predict(X_test)\n",
    "results[\"Level2_Pred\"] = model2.predict(X_test)\n",
    "results[\"Level3_Pred\"] = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level1_Pred</th>\n",
       "      <th>Level2_Pred</th>\n",
       "      <th>Level3_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4C3D8686</td>\n",
       "      <td>74974</td>\n",
       "      <td>62E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69286F45</td>\n",
       "      <td>2D5A3</td>\n",
       "      <td>28A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EFEF723B</td>\n",
       "      <td>CB803</td>\n",
       "      <td>627D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69286F45</td>\n",
       "      <td>2D5A3</td>\n",
       "      <td>28A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAC8EE56</td>\n",
       "      <td>9B69F</td>\n",
       "      <td>80C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>AA6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>EFEF723B</td>\n",
       "      <td>02FA0</td>\n",
       "      <td>078B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>35E04739</td>\n",
       "      <td>B2DB4</td>\n",
       "      <td>21DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>014303D1</td>\n",
       "      <td>36080</td>\n",
       "      <td>C5B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>4513C920</td>\n",
       "      <td>375FE</td>\n",
       "      <td>AA6B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2128 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       4C3D8686       74974        62E8\n",
       "1       69286F45       2D5A3        28A7\n",
       "2       EFEF723B       CB803        627D\n",
       "3       69286F45       2D5A3        28A7\n",
       "4       AAC8EE56       9B69F        80C4\n",
       "...          ...         ...         ...\n",
       "2123    09BF5150       C7E19        AA6B\n",
       "2124    EFEF723B       02FA0        078B\n",
       "2125    35E04739       B2DB4        21DA\n",
       "2126    014303D1       36080        C5B4\n",
       "2127    4513C920       375FE        AA6B\n",
       "\n",
       "[2128 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## After you add the predictions to the results dataframe\n",
    "## they should look like this\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level (4 marks)\n",
    "Now you have the predictions for each level (in the test data), and you also have the actual levels, you can compute the accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8355263157894737"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(results['Level1_Pred'],y_test['Level_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7443609022556391"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Level 2 accuracy\n",
    "accuracy_score(results['Level2_Pred'],y_test['Level_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7359022556390977"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Level 3 accuracy\n",
    "accuracy_score(results['Level3_Pred'],y_test['Level_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that level 2 had less accuracy than level 1 and level 3 had less accuracy than level 2 explained with the less categs availble in the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
